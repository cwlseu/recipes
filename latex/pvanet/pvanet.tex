\documentclass{beamer}
\usepackage{ctex}
\usepackage{graphicx}
\usepackage{amsmath}
\setbeamertemplate{caption}[numbered]

%\usetheme{default}
%\usetheme{AnnArbor} % 黄蓝色
%\usetheme{Antibes}
%\usetheme{Bergen} % 左侧边栏列主要内容标题
%\usetheme{Berkeley}
%\usetheme{Berlin}
%\usetheme{Boadilla}
%\usetheme{CambridgeUS} % 红色的而且具有影子的
%\usetheme{Copenhagen}
%\usetheme{Darmstadt}
%\usetheme{Dresden}
%\usetheme{Frankfurt}
%\usetheme{Goettingen} % 右侧边栏，淡蓝色
%\usetheme{Hannover} % 左侧边栏，淡蓝色
%\usetheme{Ilmenau}
%\usetheme{JuanLesPins}
%\usetheme{Luebeck}
\usetheme{Madrid}
%\usetheme{Malmoe}
%\usetheme{Marburg}
%\usetheme{Montpellier}
%\usetheme{PaloAlto}
%\usetheme{Pittsburgh} % 标题偏左
%\usetheme{Rochester} % 标题底色为深蓝色
%\usetheme{Singapore}
%\usetheme{Szeged}
%\usetheme{Warsaw}


\title[PVANET]{PVANET: Deep but Lightweight Neural Networks for Real-time Object Detection}
\author{Kye-Hyeon Kim; Sanghoon Hong; Byungseok Roh}

\institute[Intel Imaging and Camera Technology]
{
Intel Imaging and Camera Technology \\
\medskip
\textit{\{kye-hyeon.kim, sanghoon.hong, peter.roh\}@intel.com} % Your email address
\center{Report By: \emph{Cao Wenlong}}
}

\date{\today} % Date, can be changed to a custom date

\begin{document}
\small
\begin{frame}
\titlepage % Print the title page as the first slide

\end{frame}

\begin{frame}
\frametitle{Overview} % Table of contents slide, comment this block out to remove it
\tableofcontents % Throughout your presentation, if you choose to use \section{} and \subsection{} commands, these will automatically be printed on this slide as an overview of your presentation
\end{frame}

\section{Introduction}
\subsection{Abstract}
\begin{frame}
\frametitle{Abstract}
\begin{itemize}
\item 使用"Feature Extraction+Region Proposal+RoI Classification" 的结构，主要对Feature Extraction进行重新设计。因为，Region Proposal部分计算量不太大而且classification部分可以使用通用的技术(例如：Truncated SVD) 进行有效的压缩。
\item 设计原则：Less channels with more layers 和采用一些Building blocks （包括：串级的ReLU、Inception和HyperNet)
\end{itemize}
\begin{block}{结果}
VOC2007―83.8\%mAP；VOC2012―82.5\%mAP，46ms/image在NVIDIA Titan X GPU；
            计算量是ResNet-101的12.3\% (理论上)
\end{block}
\end{frame}


\subsection{Introduction}
\begin{frame}
\frametitle{Introduction}
 准确率很高的检测算法有往往需要很大的计算量。现在压缩和量化技术的发展对减小网络的计算量很重要。这篇文章展示了我们用于目标检测的一个轻量级的特征提取的网络结构―\emph{PVANET}
\begin{itemize}
\item 串级的ReLU\cite{hong2016pvanet}(C.ReLU―Concatenated rectified linear unit)被用在我们的CNNs 的初期阶段来减少一半的计算数量而不损失精度。
\item Inception\cite{GoogLeNet}被用在剩下的生成feature的子网络中。一个Inception module 产生不同大小的感受野（receptive fields）的输出激活值，所以增加前一层感受野大小的变化。我们观察叠加的Inception modules可以比线性链式的CNNs更有效的捕捉大范围的大小变化的目标。
\item 采用multi-scale representation的思想\cite{HyperNet}, 结合多个中间的输出，所以，这使得可以同时考虑多个level的细节和非线性。我们展示设计的网络deep and thin，在batch normalization、residual connections和基于plateau detection的learning rate的调整的帮助下进行有效地训练
\end{itemize}
\end{frame}


\subsection{Review Related Work}
\begin{frame}
\frametitle{Review:HyperNet}
\begin{figure}
  \centering
  \includegraphics[width=4.5in]{./img/HyperNet.jpg}
  \caption{HyperNet的网络结构示意图}
  \label{fig:HyperNet Structure}
\end{figure}
\end{frame}

\begin{frame}
\frametitle{Review:Inception}
\begin{figure}
  \centering
  \includegraphics[width=3.5in]{./img/Inception.jpg}
  \caption{Inception的网络结构示意图}
  \label{fig:Inception Structure}
\end{figure}
\end{frame}


\section{Nerual Network Design}
\subsection{C.ReLU}
\begin{frame}
%\frametitle{Design Details}
\begin{columns}[c]

\column{.6\textwidth} % Left column and width
    C.ReLU来源于CNN中间激活模式引发的。观察发现，输出节点倾向于是"配对的"，一个节点激活是另一个节点的相反面。
    \begin{block}{求同}
    C.ReLU减少一半输出通数量，通过简单的连接相同的输出和negation 使其变成双倍，这使得2倍的速度提升而没有损失精度
    \end{block}
    \begin{block}{存异}
    同时，增加了scaling and shifting在concatenation之后，这允许每个channel 的斜率和激活阈值与其相反的channel不同。
    \end{block}

\column{.4\textwidth} % Right column and width
    \begin{figure}
      \includegraphics[height=1.5in]{./img/CReLU.jpg}
      \caption{C.ReLU的设计结构}
      \label{fig:C.ReLU Structure}
    \end{figure}
\end{columns}
\end{frame}

\subsection{Inception}
\begin{frame}
\begin{block}{}
Inception是捕获图像中小目标和大目标的最具有成效的Building Blocks之一;\\
为了学习捕获大目标的视觉模式，CNN特征应该对应于足够大的感受野，这可以很容易的通过叠加 3x3或者更大的核卷积实现;\\
为了捕获小尺寸的物体，输出特征应该对应于足够小的感受野来精确定位小的感兴趣区域。
\end{block}

\begin{figure}
  \centering
  \includegraphics[width=4.7in]{./img/PVANET_Inception.jpg}
  \caption{(Left) Our Inception building block. 5x5 convolution is replaced with two 3x3 convolutional layers for efficiency. (Right) Inception for reducing feature map size by half}
  \label{fig:PVANET Inception Structure}
\end{figure}

\end{frame}


\begin{frame}
1x1的conv扮演了关键的角色，保留上一层的感受野。只是增加输入模式的非线性，它减慢了一些输出特征的感受野的增长，使得可以精确地捕获小尺寸的目标。
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.7in]{./img/ReceptionField.jpg}
  \caption{Inception中的感受野的直观表示}\label{fig:Reception Field size}
\end{figure}
\end{frame}

\begin{frame}
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.5in]{./img/PVANETDetails.jpg}
  \caption{The detailed structure of PVANET}
  \label{tab:PVANET details}
\end{figure}
\end{frame}

\section{Experimental Results}
\begin{frame}
\frametitle{Experimental Results}
\begin{figure}
  \centering
  % Requires \usepackage{graphicx}
  \includegraphics[width=4.5in]{./img/Result.jpg}\\
  \caption{Comparisons between our network and some state-of-the-arts in the PASCAL VOC2012 leaderboard.}\label{tab:Result}
\end{figure}
\end{frame}

\section{Summary}
\begin{frame}
\frametitle{Summary}
\begin{itemize}
  \item C.ReLU减少训练过程中的网络大小
  \item Inception是网络设计中的用于压缩网络的技巧
  \item 1x1的使用相当于挖掘卷积结果中的冗余信息，从而减少channel个数
\end{itemize}
\end{frame}



%%%% reference frame
\begin{frame}
\frametitle{References}
    \bibliographystyle{plain}
    \bibliography{ref/ref}
\end{frame}

\end{document}
